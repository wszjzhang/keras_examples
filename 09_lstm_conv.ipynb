{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script demonstrates the use of a convolutional LSTM network.\n",
    "This network is used to predict the next frame of an artificially\n",
    "generated movie which contains moving squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We create a layer which take as input movies of shape\n",
    "# (n_frames, width, height, channels) and returns a movie\n",
    "# of identical shape.\n",
    "\n",
    "seq = Sequential()\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   input_shape=(None, 40, 40, 1),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
    "               activation='sigmoid',\n",
    "               padding='same', data_format='channels_last'))\n",
    "seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     18
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Artificial data generation:\n",
    "# Generate movies with 3 to 7 moving squares inside.\n",
    "# The squares are of shape 1x1 or 2x2 pixels,\n",
    "# which move linearly over time.\n",
    "# For convenience we first create movies with bigger width and height (80x80)\n",
    "# and at the end we select a 40x40 window.\n",
    "\n",
    "def generate_movies(n_samples=1200, n_frames=15):\n",
    "    row = 80\n",
    "    col = 80\n",
    "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
    "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),\n",
    "                              dtype=np.float)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Add 3 to 7 moving squares\n",
    "        n = np.random.randint(3, 8)\n",
    "\n",
    "        for j in range(n):\n",
    "            # Initial position\n",
    "            xstart = np.random.randint(20, 60)\n",
    "            ystart = np.random.randint(20, 60)\n",
    "            # Direction of motion\n",
    "            directionx = np.random.randint(0, 3) - 1\n",
    "            directiony = np.random.randint(0, 3) - 1\n",
    "\n",
    "            # Size of the square\n",
    "            w = np.random.randint(2, 4)\n",
    "\n",
    "            for t in range(n_frames):\n",
    "                x_shift = xstart + directionx * t\n",
    "                y_shift = ystart + directiony * t\n",
    "                noisy_movies[i, t, x_shift - w: x_shift + w,\n",
    "                             y_shift - w: y_shift + w, 0] += 1\n",
    "\n",
    "                # Make it more robust by adding noise.\n",
    "                # The idea is that if during inference,\n",
    "                # the value of the pixel is not exactly one,\n",
    "                # we need to train the network to be robust and still\n",
    "                # consider it as a pixel belonging to a square.\n",
    "                if np.random.randint(0, 2):\n",
    "                    noise_f = (-1)**np.random.randint(0, 2)\n",
    "                    noisy_movies[i, t,\n",
    "                                 x_shift - w - 1: x_shift + w + 1,\n",
    "                                 y_shift - w - 1: y_shift + w + 1,\n",
    "                                 0] += noise_f * 0.1\n",
    "\n",
    "                # Shift the ground truth by 1\n",
    "                x_shift = xstart + directionx * (t + 1)\n",
    "                y_shift = ystart + directiony * (t + 1)\n",
    "                shifted_movies[i, t, x_shift - w: x_shift + w,\n",
    "                               y_shift - w: y_shift + w, 0] += 1\n",
    "\n",
    "    # Cut to a 40x40 window\n",
    "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
    "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
    "    noisy_movies[noisy_movies >= 1] = 1\n",
    "    shifted_movies[shifted_movies >= 1] = 1\n",
    "    return noisy_movies, shifted_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 950 samples, validate on 50 samples\n",
      "Epoch 1/300\n",
      "950/950 [==============================] - 75s - loss: 0.3310 - val_loss: 0.5585\n",
      "Epoch 2/300\n",
      "950/950 [==============================] - 72s - loss: 0.0529 - val_loss: 0.3426\n",
      "Epoch 3/300\n",
      "950/950 [==============================] - 72s - loss: 0.0132 - val_loss: 0.2674\n",
      "Epoch 4/300\n",
      "950/950 [==============================] - 72s - loss: 0.0092 - val_loss: 0.2118\n",
      "Epoch 5/300\n",
      "950/950 [==============================] - 72s - loss: 0.0029 - val_loss: 0.1340\n",
      "Epoch 6/300\n",
      "950/950 [==============================] - 72s - loss: 0.0015 - val_loss: 0.0372\n",
      "Epoch 7/300\n",
      "950/950 [==============================] - 72s - loss: 8.6486e-04 - val_loss: 0.0025\n",
      "Epoch 8/300\n",
      "950/950 [==============================] - 72s - loss: 6.0073e-04 - val_loss: 6.6850e-04\n",
      "Epoch 9/300\n",
      "950/950 [==============================] - 72s - loss: 4.5901e-04 - val_loss: 5.4579e-04\n",
      "Epoch 10/300\n",
      "950/950 [==============================] - 72s - loss: 3.8745e-04 - val_loss: 3.6267e-04\n",
      "Epoch 11/300\n",
      "950/950 [==============================] - 72s - loss: 3.3530e-04 - val_loss: 3.1909e-04\n",
      "Epoch 12/300\n",
      "950/950 [==============================] - 72s - loss: 2.9420e-04 - val_loss: 2.6925e-04\n",
      "Epoch 13/300\n",
      "950/950 [==============================] - 72s - loss: 2.6997e-04 - val_loss: 2.5730e-04\n",
      "Epoch 14/300\n",
      "950/950 [==============================] - 72s - loss: 2.3634e-04 - val_loss: 2.5299e-04\n",
      "Epoch 15/300\n",
      "950/950 [==============================] - 72s - loss: 2.2292e-04 - val_loss: 2.2051e-04\n",
      "Epoch 16/300\n",
      "950/950 [==============================] - 72s - loss: 2.0239e-04 - val_loss: 2.0528e-04\n",
      "Epoch 17/300\n",
      "950/950 [==============================] - 72s - loss: 1.8961e-04 - val_loss: 2.5996e-04\n",
      "Epoch 18/300\n",
      "950/950 [==============================] - 72s - loss: 1.7965e-04 - val_loss: 1.8085e-04\n",
      "Epoch 19/300\n",
      "950/950 [==============================] - 72s - loss: 1.6941e-04 - val_loss: 1.8115e-04\n",
      "Epoch 20/300\n",
      "950/950 [==============================] - 72s - loss: 1.5913e-04 - val_loss: 1.7364e-04\n",
      "Epoch 21/300\n",
      "950/950 [==============================] - 72s - loss: 1.5297e-04 - val_loss: 1.7526e-04\n",
      "Epoch 22/300\n",
      "950/950 [==============================] - 72s - loss: 1.4609e-04 - val_loss: 1.6354e-04\n",
      "Epoch 23/300\n",
      "950/950 [==============================] - 72s - loss: 1.3913e-04 - val_loss: 1.5203e-04\n",
      "Epoch 24/300\n",
      "950/950 [==============================] - 72s - loss: 1.3229e-04 - val_loss: 1.4758e-04\n",
      "Epoch 25/300\n",
      "950/950 [==============================] - 72s - loss: 1.2498e-04 - val_loss: 1.3682e-04\n",
      "Epoch 26/300\n",
      "950/950 [==============================] - 71s - loss: 1.2460e-04 - val_loss: 1.4380e-04\n",
      "Epoch 27/300\n",
      "950/950 [==============================] - 72s - loss: 1.1568e-04 - val_loss: 1.3914e-04\n",
      "Epoch 28/300\n",
      "950/950 [==============================] - 71s - loss: 1.1183e-04 - val_loss: 1.4175e-04\n",
      "Epoch 29/300\n",
      "950/950 [==============================] - 71s - loss: 1.0735e-04 - val_loss: 1.3664e-04\n",
      "Epoch 30/300\n",
      "950/950 [==============================] - 71s - loss: 1.0373e-04 - val_loss: 2.1294e-04\n",
      "Epoch 31/300\n",
      "950/950 [==============================] - 71s - loss: 1.0167e-04 - val_loss: 1.3016e-04\n",
      "Epoch 32/300\n",
      "950/950 [==============================] - 71s - loss: 9.6644e-05 - val_loss: 1.2637e-04\n",
      "Epoch 33/300\n",
      "950/950 [==============================] - 71s - loss: 9.4371e-05 - val_loss: 1.3647e-04\n",
      "Epoch 34/300\n",
      "950/950 [==============================] - 71s - loss: 8.9055e-05 - val_loss: 1.1762e-04\n",
      "Epoch 35/300\n",
      "950/950 [==============================] - 72s - loss: 8.7746e-05 - val_loss: 1.2774e-04\n",
      "Epoch 36/300\n",
      "950/950 [==============================] - 72s - loss: 8.2280e-05 - val_loss: 1.3698e-04\n",
      "Epoch 37/300\n",
      "950/950 [==============================] - 72s - loss: 8.2699e-05 - val_loss: 1.1188e-04\n",
      "Epoch 38/300\n",
      "950/950 [==============================] - 72s - loss: 7.7752e-05 - val_loss: 1.0843e-04\n",
      "Epoch 39/300\n",
      "950/950 [==============================] - 72s - loss: 7.6186e-05 - val_loss: 1.3323e-04\n",
      "Epoch 40/300\n",
      "950/950 [==============================] - 72s - loss: 7.4103e-05 - val_loss: 1.1082e-04\n",
      "Epoch 41/300\n",
      "950/950 [==============================] - 72s - loss: 7.3388e-05 - val_loss: 1.0368e-04\n",
      "Epoch 42/300\n",
      "950/950 [==============================] - 72s - loss: 7.0884e-05 - val_loss: 1.2515e-04\n",
      "Epoch 43/300\n",
      "950/950 [==============================] - 72s - loss: 6.8016e-05 - val_loss: 1.0327e-04\n",
      "Epoch 44/300\n",
      "950/950 [==============================] - 72s - loss: 6.8094e-05 - val_loss: 1.1592e-04\n",
      "Epoch 45/300\n",
      "950/950 [==============================] - 72s - loss: 6.4185e-05 - val_loss: 9.9517e-05\n",
      "Epoch 46/300\n",
      "950/950 [==============================] - 72s - loss: 6.3214e-05 - val_loss: 1.0181e-04\n",
      "Epoch 47/300\n",
      "950/950 [==============================] - 72s - loss: 5.8947e-05 - val_loss: 3.1059e-04\n",
      "Epoch 48/300\n",
      "950/950 [==============================] - 72s - loss: 6.1501e-05 - val_loss: 1.1041e-04\n",
      "Epoch 49/300\n",
      "950/950 [==============================] - 72s - loss: 5.7199e-05 - val_loss: 1.2727e-04\n",
      "Epoch 50/300\n",
      "950/950 [==============================] - 72s - loss: 5.7247e-05 - val_loss: 9.7016e-05\n",
      "Epoch 51/300\n",
      "950/950 [==============================] - 72s - loss: 5.5542e-05 - val_loss: 1.2252e-04\n",
      "Epoch 52/300\n",
      "950/950 [==============================] - 72s - loss: 5.2235e-05 - val_loss: 1.0136e-04\n",
      "Epoch 53/300\n",
      "950/950 [==============================] - 72s - loss: 5.1603e-05 - val_loss: 9.9918e-05\n",
      "Epoch 54/300\n",
      "950/950 [==============================] - 71s - loss: 5.0764e-05 - val_loss: 8.8670e-05\n",
      "Epoch 55/300\n",
      "950/950 [==============================] - 71s - loss: 4.8723e-05 - val_loss: 1.0904e-04\n",
      "Epoch 56/300\n",
      "950/950 [==============================] - 71s - loss: 4.8185e-05 - val_loss: 1.0973e-04\n",
      "Epoch 57/300\n",
      "950/950 [==============================] - 71s - loss: 4.5788e-05 - val_loss: 9.3042e-05\n",
      "Epoch 58/300\n",
      "950/950 [==============================] - 71s - loss: 4.5839e-05 - val_loss: 8.6915e-05\n",
      "Epoch 59/300\n",
      "950/950 [==============================] - 71s - loss: 4.3371e-05 - val_loss: 8.4690e-05\n",
      "Epoch 60/300\n",
      "950/950 [==============================] - 71s - loss: 4.2122e-05 - val_loss: 8.7545e-05\n",
      "Epoch 61/300\n",
      "950/950 [==============================] - 71s - loss: 4.4184e-05 - val_loss: 1.2519e-04\n",
      "Epoch 62/300\n",
      "950/950 [==============================] - 71s - loss: 4.1156e-05 - val_loss: 9.3276e-05\n",
      "Epoch 63/300\n",
      "950/950 [==============================] - 71s - loss: 3.9551e-05 - val_loss: 1.0845e-04\n",
      "Epoch 64/300\n",
      "950/950 [==============================] - 72s - loss: 4.0343e-05 - val_loss: 1.1630e-04\n",
      "Epoch 65/300\n",
      "950/950 [==============================] - 71s - loss: 3.8010e-05 - val_loss: 9.9562e-05\n",
      "Epoch 66/300\n",
      "950/950 [==============================] - 71s - loss: 3.7253e-05 - val_loss: 8.3995e-05\n",
      "Epoch 67/300\n",
      "950/950 [==============================] - 71s - loss: 3.6686e-05 - val_loss: 1.2120e-04\n",
      "Epoch 68/300\n",
      "950/950 [==============================] - 71s - loss: 3.5553e-05 - val_loss: 9.4548e-05\n",
      "Epoch 69/300\n",
      "950/950 [==============================] - 72s - loss: 3.4469e-05 - val_loss: 8.7418e-05\n",
      "Epoch 70/300\n",
      "950/950 [==============================] - 71s - loss: 3.3210e-05 - val_loss: 1.2016e-04\n",
      "Epoch 71/300\n",
      "950/950 [==============================] - 72s - loss: 3.2829e-05 - val_loss: 9.4030e-05\n",
      "Epoch 72/300\n",
      "950/950 [==============================] - 72s - loss: 3.2952e-05 - val_loss: 8.8313e-05\n",
      "Epoch 73/300\n",
      "950/950 [==============================] - 72s - loss: 3.1115e-05 - val_loss: 8.4836e-05\n",
      "Epoch 74/300\n",
      "950/950 [==============================] - 72s - loss: 3.0650e-05 - val_loss: 8.1963e-05\n",
      "Epoch 75/300\n",
      "950/950 [==============================] - 72s - loss: 2.8953e-05 - val_loss: 7.7666e-05\n",
      "Epoch 76/300\n",
      "950/950 [==============================] - 72s - loss: 2.9060e-05 - val_loss: 7.8788e-05\n",
      "Epoch 77/300\n",
      "950/950 [==============================] - 71s - loss: 2.7785e-05 - val_loss: 7.6328e-05\n",
      "Epoch 78/300\n",
      "950/950 [==============================] - 71s - loss: 2.9103e-05 - val_loss: 7.8241e-05\n",
      "Epoch 79/300\n",
      "950/950 [==============================] - 71s - loss: 2.6899e-05 - val_loss: 9.1398e-05\n",
      "Epoch 80/300\n",
      "950/950 [==============================] - 72s - loss: 2.7021e-05 - val_loss: 8.7613e-05\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950/950 [==============================] - 71s - loss: 2.6448e-05 - val_loss: 7.2738e-05\n",
      "Epoch 82/300\n",
      "950/950 [==============================] - 71s - loss: 2.6030e-05 - val_loss: 8.0155e-05\n",
      "Epoch 83/300\n",
      "950/950 [==============================] - 71s - loss: 2.5546e-05 - val_loss: 8.5529e-05\n",
      "Epoch 84/300\n",
      "950/950 [==============================] - 72s - loss: 2.3341e-05 - val_loss: 7.0721e-05\n",
      "Epoch 85/300\n",
      "950/950 [==============================] - 71s - loss: 2.4018e-05 - val_loss: 7.6305e-05\n",
      "Epoch 86/300\n",
      "950/950 [==============================] - 71s - loss: 2.3363e-05 - val_loss: 8.1086e-05\n",
      "Epoch 87/300\n",
      "950/950 [==============================] - 71s - loss: 2.3243e-05 - val_loss: 7.8588e-05\n",
      "Epoch 88/300\n",
      "950/950 [==============================] - 71s - loss: 2.3405e-05 - val_loss: 9.1898e-05\n",
      "Epoch 89/300\n",
      "950/950 [==============================] - 71s - loss: 2.2560e-05 - val_loss: 7.7779e-05\n",
      "Epoch 90/300\n",
      "950/950 [==============================] - 71s - loss: 2.0084e-05 - val_loss: 7.6796e-05\n",
      "Epoch 91/300\n",
      "950/950 [==============================] - 71s - loss: 2.0449e-05 - val_loss: 7.7697e-05\n",
      "Epoch 92/300\n",
      "950/950 [==============================] - 71s - loss: 2.0522e-05 - val_loss: 7.6994e-05\n",
      "Epoch 93/300\n",
      "950/950 [==============================] - 71s - loss: 2.1047e-05 - val_loss: 9.3478e-05\n",
      "Epoch 94/300\n",
      "950/950 [==============================] - 71s - loss: 1.9164e-05 - val_loss: 1.0809e-04\n",
      "Epoch 95/300\n",
      "950/950 [==============================] - 71s - loss: 1.8432e-05 - val_loss: 7.5455e-05\n",
      "Epoch 96/300\n",
      "950/950 [==============================] - 71s - loss: 1.9069e-05 - val_loss: 7.9188e-05\n",
      "Epoch 97/300\n",
      "950/950 [==============================] - 71s - loss: 1.7879e-05 - val_loss: 8.0908e-05\n",
      "Epoch 98/300\n",
      "950/950 [==============================] - 71s - loss: 1.8701e-05 - val_loss: 7.5188e-05\n",
      "Epoch 99/300\n",
      "950/950 [==============================] - 71s - loss: 1.8495e-05 - val_loss: 7.6320e-05\n",
      "Epoch 100/300\n",
      "950/950 [==============================] - 72s - loss: 1.6972e-05 - val_loss: 7.6352e-05\n",
      "Epoch 101/300\n",
      "950/950 [==============================] - 72s - loss: 1.6776e-05 - val_loss: 7.6728e-05\n",
      "Epoch 102/300\n",
      "950/950 [==============================] - 72s - loss: 1.6105e-05 - val_loss: 7.3680e-05\n",
      "Epoch 103/300\n",
      "950/950 [==============================] - 72s - loss: 1.6232e-05 - val_loss: 7.2491e-05\n",
      "Epoch 104/300\n",
      "950/950 [==============================] - 72s - loss: 1.6545e-05 - val_loss: 7.2304e-05\n",
      "Epoch 105/300\n",
      "950/950 [==============================] - 72s - loss: 1.5678e-05 - val_loss: 7.5283e-05\n",
      "Epoch 106/300\n",
      "950/950 [==============================] - 72s - loss: 1.5044e-05 - val_loss: 7.8058e-05\n",
      "Epoch 107/300\n",
      "950/950 [==============================] - 72s - loss: 1.4143e-05 - val_loss: 6.8233e-05\n",
      "Epoch 108/300\n",
      "950/950 [==============================] - 72s - loss: 1.5242e-05 - val_loss: 7.3293e-05\n",
      "Epoch 109/300\n",
      "950/950 [==============================] - 72s - loss: 1.4179e-05 - val_loss: 7.3676e-05\n",
      "Epoch 110/300\n",
      "950/950 [==============================] - 72s - loss: 1.4855e-05 - val_loss: 7.7737e-05\n",
      "Epoch 111/300\n",
      "950/950 [==============================] - 72s - loss: 1.4351e-05 - val_loss: 1.1423e-04\n",
      "Epoch 112/300\n",
      "950/950 [==============================] - 72s - loss: 1.3294e-05 - val_loss: 7.4530e-05\n",
      "Epoch 113/300\n",
      "950/950 [==============================] - 72s - loss: 1.2432e-05 - val_loss: 7.3299e-05\n",
      "Epoch 114/300\n",
      "950/950 [==============================] - 72s - loss: 1.2662e-05 - val_loss: 7.7781e-05\n",
      "Epoch 115/300\n",
      "950/950 [==============================] - 72s - loss: 1.2562e-05 - val_loss: 8.2548e-05\n",
      "Epoch 116/300\n",
      "950/950 [==============================] - 71s - loss: 1.2087e-05 - val_loss: 7.8543e-05\n",
      "Epoch 117/300\n",
      "950/950 [==============================] - 71s - loss: 1.2042e-05 - val_loss: 7.7586e-05\n",
      "Epoch 118/300\n",
      "950/950 [==============================] - 71s - loss: 1.2094e-05 - val_loss: 7.2884e-05\n",
      "Epoch 119/300\n",
      "950/950 [==============================] - 71s - loss: 1.1433e-05 - val_loss: 1.0585e-04\n",
      "Epoch 120/300\n",
      "950/950 [==============================] - 72s - loss: 1.1958e-05 - val_loss: 7.3646e-05\n",
      "Epoch 121/300\n",
      "950/950 [==============================] - 72s - loss: 1.1274e-05 - val_loss: 7.2344e-05\n",
      "Epoch 122/300\n",
      "950/950 [==============================] - 132s - loss: 1.2398e-05 - val_loss: 7.6854e-05\n",
      "Epoch 123/300\n",
      "950/950 [==============================] - 366s - loss: 1.0995e-05 - val_loss: 7.1504e-05\n",
      "Epoch 124/300\n",
      "950/950 [==============================] - 364s - loss: 1.1038e-05 - val_loss: 7.2414e-05\n",
      "Epoch 125/300\n",
      "950/950 [==============================] - 364s - loss: 9.9839e-06 - val_loss: 7.7808e-05\n",
      "Epoch 126/300\n",
      "950/950 [==============================] - 364s - loss: 1.0204e-05 - val_loss: 7.1941e-05\n",
      "Epoch 127/300\n",
      "950/950 [==============================] - 363s - loss: 1.0232e-05 - val_loss: 7.2156e-05\n",
      "Epoch 128/300\n",
      "950/950 [==============================] - 364s - loss: 1.0287e-05 - val_loss: 6.9951e-05\n",
      "Epoch 129/300\n",
      "950/950 [==============================] - 362s - loss: 1.0238e-05 - val_loss: 7.0763e-05\n",
      "Epoch 130/300\n",
      "950/950 [==============================] - 363s - loss: 9.3242e-06 - val_loss: 7.4739e-05\n",
      "Epoch 131/300\n",
      "950/950 [==============================] - 362s - loss: 9.4600e-06 - val_loss: 7.9583e-05\n",
      "Epoch 132/300\n",
      "950/950 [==============================] - 361s - loss: 9.7429e-06 - val_loss: 7.6449e-05\n",
      "Epoch 133/300\n",
      "950/950 [==============================] - 362s - loss: 9.2945e-06 - val_loss: 7.7628e-05\n",
      "Epoch 134/300\n",
      "950/950 [==============================] - 362s - loss: 9.0876e-06 - val_loss: 7.0126e-05\n",
      "Epoch 135/300\n",
      "950/950 [==============================] - 361s - loss: 9.0709e-06 - val_loss: 7.2701e-05\n",
      "Epoch 136/300\n",
      "950/950 [==============================] - 360s - loss: 8.8177e-06 - val_loss: 7.4334e-05\n",
      "Epoch 137/300\n",
      "950/950 [==============================] - 361s - loss: 8.8722e-06 - val_loss: 7.1235e-05\n",
      "Epoch 138/300\n",
      "950/950 [==============================] - 21421s - loss: 8.4831e-06 - val_loss: 7.1442e-05\n",
      "Epoch 139/300\n",
      "950/950 [==============================] - 70s - loss: 8.0966e-06 - val_loss: 7.1639e-05\n",
      "Epoch 140/300\n",
      "950/950 [==============================] - 71s - loss: 8.5434e-06 - val_loss: 9.4351e-05\n",
      "Epoch 141/300\n",
      "950/950 [==============================] - 71s - loss: 7.9613e-06 - val_loss: 7.3882e-05\n",
      "Epoch 142/300\n",
      "950/950 [==============================] - 72s - loss: 7.8513e-06 - val_loss: 7.0922e-05\n",
      "Epoch 143/300\n",
      "950/950 [==============================] - 72s - loss: 7.6503e-06 - val_loss: 7.7398e-05\n",
      "Epoch 144/300\n",
      "950/950 [==============================] - 71s - loss: 7.6816e-06 - val_loss: 6.9187e-05\n",
      "Epoch 145/300\n",
      "950/950 [==============================] - 72s - loss: 7.4489e-06 - val_loss: 7.0715e-05\n",
      "Epoch 146/300\n",
      "950/950 [==============================] - 72s - loss: 7.5539e-06 - val_loss: 1.0003e-04\n",
      "Epoch 147/300\n",
      "950/950 [==============================] - 73s - loss: 7.5103e-06 - val_loss: 7.3712e-05\n",
      "Epoch 148/300\n",
      "950/950 [==============================] - 73s - loss: 7.3872e-06 - val_loss: 6.9407e-05\n",
      "Epoch 149/300\n",
      "950/950 [==============================] - 73s - loss: 7.5145e-06 - val_loss: 7.4283e-05\n",
      "Epoch 150/300\n",
      "950/950 [==============================] - 72s - loss: 6.9185e-06 - val_loss: 6.8307e-05\n",
      "Epoch 151/300\n",
      "950/950 [==============================] - 72s - loss: 7.1862e-06 - val_loss: 7.4920e-05\n",
      "Epoch 152/300\n",
      "950/950 [==============================] - 71s - loss: 6.7433e-06 - val_loss: 6.9300e-05\n",
      "Epoch 153/300\n",
      "100/950 [==>...........................] - ETA: 62s - loss: 6.6366e-06"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "noisy_movies, shifted_movies = generate_movies(n_samples=1200)\n",
    "seq.fit(noisy_movies[:1000], shifted_movies[:1000], batch_size=10,\n",
    "        epochs=300, validation_split=0.05)\n",
    "\n",
    "# Testing the network on one movie\n",
    "# feed it with the first 7 positions and then\n",
    "# predict the new positions\n",
    "which = 1004\n",
    "track = noisy_movies[which][:7, ::, ::, ::]\n",
    "\n",
    "for j in range(16):\n",
    "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
    "    new = new_pos[::, -1, ::, ::, ::]\n",
    "    track = np.concatenate((track, new), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And then compare the predictions\n",
    "# to the ground truth\n",
    "track2 = noisy_movies[which][::, ::, ::, ::]\n",
    "for i in range(15):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "    ax = fig.add_subplot(121)\n",
    "\n",
    "    if i >= 7:\n",
    "        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n",
    "    else:\n",
    "        ax.text(1, 3, 'Initial trajectory', fontsize=20)\n",
    "\n",
    "    toplot = track[i, ::, ::, 0]\n",
    "\n",
    "    plt.imshow(toplot)\n",
    "    ax = fig.add_subplot(122)\n",
    "    plt.text(1, 3, 'Ground truth', fontsize=20)\n",
    "\n",
    "    toplot = track2[i, ::, ::, 0]\n",
    "    if i >= 2:\n",
    "        toplot = shifted_movies[which][i - 1, ::, ::, 0]\n",
    "\n",
    "    plt.imshow(toplot)\n",
    "    plt.savefig('%i_animate.png' % (i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
